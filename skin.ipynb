{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Melanoma-Skin-Cancer-Detection-using-Swin-Transformer-main\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Mount Google Drive (for Colab)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m     14\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Define dataset paths - Update these to your Google Drive paths\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from transformers import SwinForImageClassification, SwinConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define dataset paths\n",
    "HAM10000_METADATA = \"D:\\\\Melanoma-Skin-Cancer-Detection-using-Swin-Transformer-main\\\\data\\\\HAM10000_metadata.csv\"\n",
    "IMAGE_DIR = \"D:\\\\Melanoma-Skin-Cancer-Detection-using-Swin-Transformer-main\\\\data\\\\HAM10000_images\"\n",
    "\n",
    "# Load and process metadata\n",
    "df = pd.read_csv(HAM10000_METADATA)\n",
    "label_mapping = {'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}\n",
    "df[\"label\"] = df[\"dx\"].map(label_mapping)\n",
    "\n",
    "# Split dataset into 80% train, 20% test\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Custom Dataset Class\n",
    "class SkinCancerDataset(Dataset):\n",
    "    def __init__(self, img_dir, metadata, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "        self.valid_images = [(os.path.join(img_dir, f\"{row['image_id']}.jpg\"), row['label'])\n",
    "                             for _, row in metadata.iterrows() if os.path.exists(os.path.join(img_dir, f\"{row['image_id']}.jpg\"))]\n",
    "    def __len__(self):\n",
    "        return len(self.valid_images)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.valid_images[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Create dataset & dataloaders\n",
    "train_dataset = SkinCancerDataset(IMAGE_DIR, train_df, transform=transform)\n",
    "test_dataset = SkinCancerDataset(IMAGE_DIR, test_df, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load Swin Transformer Model\n",
    "config = SwinConfig.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\", num_labels=7)\n",
    "model = SwinForImageClassification(config)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer, epochs=10)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"swin_transformer_skin_cancer.pth\")\n",
    "\n",
    "# Prediction Function\n",
    "def predict(image_path, model):\n",
    "    model.eval()\n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"Image not found!\")\n",
    "        return None \n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(image).logits\n",
    "        prediction = torch.argmax(output, dim=1).item()\n",
    "    return prediction\n",
    "\n",
    "# Example Prediction\n",
    "example_image = os.path.join(IMAGE_DIR, \"ISIC_0027413.jpg\")\n",
    "predicted_class = predict(example_image, model)\n",
    "if predicted_class is not None:\n",
    "    print(f\"Predicted Class: {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
